"""GitHubä»“åº“å†…å®¹æŠ“å–å™¨ - ä½¿ç”¨GitHub API"""
import asyncio
import aiohttp
import base64
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from urllib.parse import quote

from .config import GitHubConfig, default_config
from .utils import GitHubUtils, AsyncRateLimiter


class GitHubRepoScraper:
    """GitHubä»“åº“å†…å®¹æŠ“å–å™¨ - åŸºäºGitHub API"""
    
    def __init__(self, config: GitHubConfig = None):
        """
        åˆå§‹åŒ–GitHubä»“åº“æŠ“å–å™¨
        
        Args:
            config: é…ç½®å¯¹è±¡ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.config = config or default_config
        self.session: Optional[aiohttp.ClientSession] = None
        self.rate_limiter = AsyncRateLimiter(
            self.config.api_rate_limit, 
            3600  # æ¯å°æ—¶
        )
        
        # æ„å»ºè¯·æ±‚å¤´
        self.headers = self.config.request_headers.copy()
        if self.config.api_token:
            self.headers['Authorization'] = f'token {self.config.api_token}'
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = self.config.output_base_dir / "Repositories"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # APIç«¯ç‚¹
        self.api_base = "https://api.github.com"
        
        # æ”¯æŒçš„æ–‡ä»¶ç±»å‹
        self.text_extensions = {
            '.md', '.markdown', '.rst', '.txt', '.py', '.js', '.ts', '.java',
            '.cpp', '.c', '.h', '.hpp', '.cs', '.go', '.rs', '.rb', '.php',
            '.html', '.css', '.scss', '.sass', '.json', '.yaml', '.yml',
            '.xml', '.toml', '.ini', '.cfg', '.conf', '.sh', '.bash',
            '.dockerfile', '.makefile', '.cmake', '.gradle', '.maven'
        }
        
        # æ–‡æ¡£ç›¸å…³æ–‡ä»¶æ¨¡å¼
        self.doc_patterns = [
            'readme', 'contributing', 'changelog', 'license', 'install',
            'usage', 'api', 'guide', 'tutorial', 'example', 'demo',
            'doc', 'docs', 'documentation', 'wiki', 'faq', 'help'
        ]
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        self.session = aiohttp.ClientSession(
            headers=self.headers,
            timeout=aiohttp.ClientTimeout(total=self.config.api_timeout)
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.session:
            await self.session.close()
    
    async def get_repository_info(self, owner: str, repo: str) -> Dict[str, Any]:
        """
        è·å–ä»“åº“åŸºæœ¬ä¿¡æ¯
        
        Args:
            owner: ä»“åº“æ‰€æœ‰è€…
            repo: ä»“åº“åç§°
            
        Returns:
            ä»“åº“ä¿¡æ¯å­—å…¸
        """
        print(f"ğŸ“‹ è·å–ä»“åº“ä¿¡æ¯: {owner}/{repo}")
        
        try:
            await self.rate_limiter.acquire()
            
            url = f"{self.api_base}/repos/{owner}/{repo}"
            async with self.session.get(url) as response:
                if response.status == 200:
                    repo_data = await response.json()
                    
                    # æå–æœ‰ç”¨ä¿¡æ¯
                    return {
                        "status": "success",
                        "owner": repo_data.get("owner", {}).get("login"),
                        "name": repo_data.get("name"),
                        "full_name": repo_data.get("full_name"),
                        "description": repo_data.get("description"),
                        "language": repo_data.get("language"),
                        "languages_url": repo_data.get("languages_url"),
                        "size": repo_data.get("size"),
                        "stargazers_count": repo_data.get("stargazers_count"),
                        "forks_count": repo_data.get("forks_count"),
                        "created_at": repo_data.get("created_at"),
                        "updated_at": repo_data.get("updated_at"),
                        "pushed_at": repo_data.get("pushed_at"),
                        "default_branch": repo_data.get("default_branch"),
                        "topics": repo_data.get("topics", []),
                        "license": repo_data.get("license", {}).get("name") if repo_data.get("license") else None,
                        "has_wiki": repo_data.get("has_wiki"),
                        "has_pages": repo_data.get("has_pages"),
                        "homepage": repo_data.get("homepage"),
                        "archive_url": repo_data.get("archive_url"),
                        "contents_url": repo_data.get("contents_url"),
                        "documentation_url": repo_data.get("documentation"),
                        "fetched_at": datetime.now().isoformat()
                    }
                elif response.status == 404:
                    return {
                        "status": "not_found",
                        "owner": owner,
                        "name": repo,
                        "error": "Repository not found",
                        "fetched_at": datetime.now().isoformat()
                    }
                else:
                    return {
                        "status": "error",
                        "owner": owner,
                        "name": repo,
                        "error": f"HTTP {response.status}: {await response.text()}",
                        "fetched_at": datetime.now().isoformat()
                    }
                    
        except Exception as e:
            return {
                "status": "error",
                "owner": owner,
                "name": repo,
                "error": str(e),
                "fetched_at": datetime.now().isoformat()
            }
    
    async def get_repository_languages(self, owner: str, repo: str) -> Dict[str, int]:
        """
        è·å–ä»“åº“ä½¿ç”¨çš„ç¼–ç¨‹è¯­è¨€ç»Ÿè®¡
        
        Args:
            owner: ä»“åº“æ‰€æœ‰è€…
            repo: ä»“åº“åç§°
            
        Returns:
            è¯­è¨€ç»Ÿè®¡å­—å…¸ (è¯­è¨€å: å­—èŠ‚æ•°)
        """
        try:
            await self.rate_limiter.acquire()
            
            url = f"{self.api_base}/repos/{owner}/{repo}/languages"
            async with self.session.get(url) as response:
                if response.status == 200:
                    return await response.json()
                else:
                    return {}
        except Exception:
            return {}
    
    async def list_repository_contents(self, owner: str, repo: str, 
                                     path: str = "", 
                                     branch: str = None) -> List[Dict[str, Any]]:
        """
        åˆ—å‡ºä»“åº“ç›®å½•å†…å®¹
        
        Args:
            owner: ä»“åº“æ‰€æœ‰è€…
            repo: ä»“åº“åç§°
            path: ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤ä¸ºæ ¹ç›®å½•ï¼‰
            branch: åˆ†æ”¯åï¼ˆé»˜è®¤ä¸ºä¸»åˆ†æ”¯ï¼‰
            
        Returns:
            æ–‡ä»¶å’Œç›®å½•åˆ—è¡¨
        """
        try:
            await self.rate_limiter.acquire()
            
            url = f"{self.api_base}/repos/{owner}/{repo}/contents/{path}"
            params = {}
            if branch:
                params['ref'] = branch
            
            async with self.session.get(url, params=params) as response:
                if response.status == 200:
                    contents = await response.json()
                    
                    # å¦‚æœè¿”å›å•ä¸ªæ–‡ä»¶ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
                    if isinstance(contents, dict):
                        contents = [contents]
                    
                    return contents
                else:
                    return []
                    
        except Exception as e:
            print(f"âš ï¸ åˆ—å‡ºç›®å½•å†…å®¹å¤±è´¥ {owner}/{repo}/{path}: {e}")
            return []
    
    async def get_file_content(self, owner: str, repo: str, 
                              file_path: str, 
                              branch: str = None) -> Optional[Dict[str, Any]]:
        """
        è·å–æ–‡ä»¶å†…å®¹
        
        Args:
            owner: ä»“åº“æ‰€æœ‰è€…
            repo: ä»“åº“åç§°
            file_path: æ–‡ä»¶è·¯å¾„
            branch: åˆ†æ”¯å
            
        Returns:
            æ–‡ä»¶å†…å®¹å­—å…¸æˆ–None
        """
        try:
            await self.rate_limiter.acquire()
            
            url = f"{self.api_base}/repos/{owner}/{repo}/contents/{file_path}"
            params = {}
            if branch:
                params['ref'] = branch
            
            async with self.session.get(url, params=params) as response:
                if response.status == 200:
                    file_data = await response.json()
                    
                    # å¦‚æœæ˜¯æ–‡ä»¶ï¼ˆä¸æ˜¯ç›®å½•ï¼‰
                    if file_data.get('type') == 'file':
                        content = file_data.get('content', '')
                        encoding = file_data.get('encoding', 'base64')
                        
                        # è§£ç å†…å®¹
                        if encoding == 'base64':
                            try:
                                decoded_content = base64.b64decode(content).decode('utf-8')
                            except UnicodeDecodeError:
                                # å¦‚æœæ˜¯äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œè¿”å›base64å†…å®¹
                                decoded_content = content
                                encoding = 'base64'
                        else:
                            decoded_content = content
                        
                        return {
                            "status": "success",
                            "path": file_data.get('path'),
                            "name": file_data.get('name'),
                            "content": decoded_content,
                            "encoding": encoding,
                            "size": file_data.get('size'),
                            "sha": file_data.get('sha'),
                            "download_url": file_data.get('download_url'),
                            "html_url": file_data.get('html_url'),
                            "retrieved_at": datetime.now().isoformat()
                        }
                    else:
                        return {
                            "status": "error",
                            "path": file_path,
                            "error": "Path is a directory, not a file",
                            "retrieved_at": datetime.now().isoformat()
                        }
                elif response.status == 404:
                    return {
                        "status": "not_found",
                        "path": file_path,
                        "error": "File not found",
                        "retrieved_at": datetime.now().isoformat()
                    }
                else:
                    return {
                        "status": "error",
                        "path": file_path,
                        "error": f"HTTP {response.status}",
                        "retrieved_at": datetime.now().isoformat()
                    }
                    
        except Exception as e:
            return {
                "status": "error",
                "path": file_path,
                "error": str(e),
                "retrieved_at": datetime.now().isoformat()
            }
    
    async def scrape_repository_documentation(self, owner: str, repo: str, 
                                            max_files: int = None,
                                            include_code: bool = True) -> Dict[str, Any]:
        """
        æŠ“å–ä»“åº“çš„æ–‡æ¡£å†…å®¹
        
        Args:
            owner: ä»“åº“æ‰€æœ‰è€…
            repo: ä»“åº“åç§°
            max_files: æœ€å¤§æ–‡ä»¶æ•°é‡é™åˆ¶
            include_code: æ˜¯å¦åŒ…å«ä»£ç æ–‡ä»¶
            
        Returns:
            æŠ“å–ç»“æœå­—å…¸
        """
        max_files = max_files or self.config.repo_max_files
        
        print(f"ğŸ“š å¼€å§‹æŠ“å–ä»“åº“æ–‡æ¡£: {owner}/{repo}")
        print(f"ğŸ“Š æœ€å¤§æ–‡ä»¶æ•°: {max_files}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        repo_dir = self.output_dir / f"{owner}_{repo}"
        repo_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            # è·å–ä»“åº“åŸºæœ¬ä¿¡æ¯
            repo_info = await self.get_repository_info(owner, repo)
            if repo_info.get("status") != "success":
                return repo_info
            
            # è·å–è¯­è¨€ç»Ÿè®¡
            languages = await self.get_repository_languages(owner, repo)
            
            # é€’å½’æ”¶é›†æ‰€æœ‰æ–‡ä»¶
            all_files = await self._collect_all_files(owner, repo, "", max_files)
            
            # è¿‡æ»¤æ–‡æ¡£ç›¸å…³æ–‡ä»¶
            documentation_files = self._filter_documentation_files(all_files, include_code)
            
            print(f"ğŸ“‹ å‘ç° {len(all_files)} ä¸ªæ–‡ä»¶ï¼Œ{len(documentation_files)} ä¸ªæ–‡æ¡£æ–‡ä»¶")
            
            # æŠ“å–æ–‡ä»¶å†…å®¹
            extracted_files = []
            for i, file_info in enumerate(documentation_files[:max_files], 1):
                print(f"ğŸ“„ æŠ“å–æ–‡ä»¶ {i}/{min(len(documentation_files), max_files)}: {file_info['path']}")
                
                file_content = await self.get_file_content(owner, repo, file_info['path'])
                if file_content and file_content.get("status") == "success":
                    # æ·»åŠ æ–‡ä»¶ç±»å‹ä¿¡æ¯
                    file_content["file_type"] = self._classify_file_type(file_info['path'])
                    file_content["priority"] = self._calculate_file_priority(file_info['path'])
                    extracted_files.append(file_content)
                
                # API é™åˆ¶å»¶è¿Ÿ
                if self.config.repo_delay > 0:
                    await asyncio.sleep(self.config.repo_delay)
            
            # æŒ‰ä¼˜å…ˆçº§æ’åº
            extracted_files.sort(key=lambda x: x.get("priority", 0), reverse=True)
            
            # æ„å»ºç»“æœ
            result = {
                "status": "success",
                "repository": repo_info,
                "languages": languages,
                "scrape_summary": {
                    "total_files_found": len(all_files),
                    "documentation_files": len(documentation_files),
                    "extracted_files": len(extracted_files),
                    "scraped_at": datetime.now().isoformat(),
                    "config_used": self.config.to_dict()
                },
                "files": extracted_files
            }
            
            # ä¿å­˜ç»“æœ
            if self.config.save_metadata:
                await self._save_repository_content(result, repo_dir)
            
            return result
            
        except Exception as e:
            print(f"âŒ æŠ“å–ä»“åº“å¤±è´¥: {e}")
            return {
                "status": "error",
                "owner": owner,
                "repo": repo,
                "error": str(e),
                "scraped_at": datetime.now().isoformat()
            }
    
    async def _collect_all_files(self, owner: str, repo: str, path: str, 
                               max_files: int, collected: List = None) -> List[Dict[str, Any]]:
        """é€’å½’æ”¶é›†æ‰€æœ‰æ–‡ä»¶ä¿¡æ¯"""
        if collected is None:
            collected = []
        
        if len(collected) >= max_files:
            return collected
        
        contents = await self.list_repository_contents(owner, repo, path)
        
        for item in contents:
            if len(collected) >= max_files:
                break
            
            if item.get('type') == 'file':
                collected.append({
                    'path': item.get('path'),
                    'name': item.get('name'),
                    'size': item.get('size'),
                    'download_url': item.get('download_url'),
                    'html_url': item.get('html_url')
                })
            elif item.get('type') == 'dir':
                # é€’å½’è¿›å…¥å­ç›®å½•
                await self._collect_all_files(owner, repo, item.get('path'), 
                                            max_files, collected)
        
        return collected
    
    def _filter_documentation_files(self, files: List[Dict[str, Any]], 
                                   include_code: bool) -> List[Dict[str, Any]]:
        """è¿‡æ»¤æ–‡æ¡£ç›¸å…³æ–‡ä»¶"""
        doc_files = []
        
        for file_info in files:
            path = file_info.get('path', '').lower()
            name = file_info.get('name', '').lower()
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡æ¡£æ–‡ä»¶
            is_doc_file = False
            
            # 1. æ£€æŸ¥æ–‡æ¡£ç›¸å…³çš„æ–‡ä»¶åæ¨¡å¼
            for pattern in self.doc_patterns:
                if pattern in name or pattern in path:
                    is_doc_file = True
                    break
            
            # 2. æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
            file_ext = Path(path).suffix.lower()
            if file_ext in self.text_extensions:
                if file_ext in ['.md', '.rst', '.txt']:
                    is_doc_file = True  # æ€»æ˜¯åŒ…å«æ–‡æ¡£æ ¼å¼
                elif include_code and file_ext in self.text_extensions:
                    is_doc_file = True  # å¦‚æœåŒ…å«ä»£ç æ–‡ä»¶
            
            # 3. ç‰¹æ®Šæ–‡ä»¶ï¼ˆæ— æ‰©å±•åä½†é‡è¦ï¼‰
            if name in ['readme', 'license', 'contributing', 'changelog', 'makefile', 'dockerfile']:
                is_doc_file = True
            
            # 4. è¿‡æ»¤æ‰å¤ªå¤§çš„æ–‡ä»¶
            if file_info.get('size', 0) > self.config.max_file_size:
                is_doc_file = False
            
            if is_doc_file:
                doc_files.append(file_info)
        
        return doc_files
    
    def _classify_file_type(self, path: str) -> str:
        """åˆ†ç±»æ–‡ä»¶ç±»å‹"""
        path_lower = path.lower()
        name = Path(path).name.lower()
        ext = Path(path).suffix.lower()
        
        # æ–‡æ¡£æ–‡ä»¶
        if any(pattern in path_lower for pattern in ['readme', 'doc', 'guide', 'tutorial']):
            return "documentation"
        
        # é…ç½®æ–‡ä»¶
        if ext in ['.yaml', '.yml', '.json', '.toml', '.ini', '.cfg', '.conf']:
            return "configuration"
        
        # æ„å»ºæ–‡ä»¶
        if name in ['makefile', 'dockerfile', 'cmake'] or ext in ['.gradle', '.maven']:
            return "build"
        
        # ä»£ç æ–‡ä»¶
        if ext in ['.py', '.js', '.ts', '.java', '.cpp', '.c', '.go', '.rs', '.rb']:
            return "code"
        
        # æ ‡è®°æ–‡æ¡£
        if ext in ['.md', '.rst', '.txt']:
            return "markup"
        
        # è®¸å¯è¯å’Œæ³•å¾‹æ–‡ä»¶
        if any(pattern in name for pattern in ['license', 'copyright', 'legal']):
            return "legal"
        
        return "other"
    
    def _calculate_file_priority(self, path: str) -> int:
        """è®¡ç®—æ–‡ä»¶ä¼˜å…ˆçº§ï¼ˆç”¨äºæ’åºï¼‰"""
        path_lower = path.lower()
        name = Path(path).name.lower()
        ext = Path(path).suffix.lower()
        
        priority = 0
        
        # READMEæ–‡ä»¶æœ€é«˜ä¼˜å…ˆçº§
        if 'readme' in name:
            priority += 100
        
        # å…¶ä»–é‡è¦æ–‡æ¡£
        high_priority_patterns = ['contributing', 'changelog', 'license', 'install', 'usage', 'api']
        for pattern in high_priority_patterns:
            if pattern in name:
                priority += 80
                break
        
        # æ–‡æ¡£æ ¼å¼æ–‡ä»¶
        if ext in ['.md', '.rst']:
            priority += 60
        elif ext == '.txt':
            priority += 40
        
        # æ–‡æ¡£ç›®å½•ä¸­çš„æ–‡ä»¶
        if 'doc' in path_lower or 'guide' in path_lower:
            priority += 30
        
        # æ ¹ç›®å½•æ–‡ä»¶ä¼˜å…ˆçº§æ›´é«˜
        if '/' not in path or path.count('/') == 1:
            priority += 20
        
        # é…ç½®æ–‡ä»¶
        if ext in ['.yaml', '.yml', '.json']:
            priority += 10
        
        return priority
    
    async def _save_repository_content(self, result: Dict[str, Any], repo_dir: Path):
        """ä¿å­˜ä»“åº“å†…å®¹"""
        repo_info = result["repository"]
        
        # ä¿å­˜å…ƒæ•°æ®
        metadata = {
            "repository": repo_info,
            "languages": result["languages"],
            "scrape_summary": result["scrape_summary"]
        }
        
        metadata_file = repo_dir / "metadata.json"
        GitHubUtils.save_json(metadata, metadata_file)
        
        # ä¿å­˜æ¯ä¸ªæ–‡ä»¶çš„å†…å®¹
        files_dir = repo_dir / "files"
        files_dir.mkdir(exist_ok=True)
        
        for file_data in result["files"]:
            if file_data.get("status") == "success" and file_data.get("encoding") != "base64":
                # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
                original_path = file_data["path"]
                safe_path = GitHubUtils.sanitize_filename(original_path.replace('/', '_'), 100)
                
                file_ext = Path(original_path).suffix
                if not file_ext:
                    file_ext = '.txt'
                
                filename = f"{safe_path}{file_ext}"
                output_file = files_dir / filename
                
                # æ„å»ºæ–‡ä»¶å†…å®¹
                file_content = f"# {original_path}\n\n"
                file_content += f"**ä»“åº“**: {repo_info['full_name']}\n"
                file_content += f"**æ–‡ä»¶ç±»å‹**: {file_data.get('file_type', 'unknown')}\n"
                file_content += f"**å¤§å°**: {file_data.get('size', 0)} bytes\n"
                file_content += f"**æŠ“å–æ—¶é—´**: {file_data['retrieved_at']}\n"
                file_content += f"**åŸå§‹URL**: {file_data.get('html_url', '')}\n\n"
                file_content += "---\n\n"
                file_content += file_data["content"]
                
                # ä¿å­˜æ–‡ä»¶
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(file_content)
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self._generate_repository_summary(result, repo_dir)
        
        print(f"ğŸ“ ä»“åº“å†…å®¹å·²ä¿å­˜åˆ°: {repo_dir}")
    
    def _generate_repository_summary(self, result: Dict[str, Any], repo_dir: Path):
        """ç”Ÿæˆä»“åº“æ€»ç»“æŠ¥å‘Š"""
        summary_file = repo_dir / "README.md"
        
        repo = result["repository"]
        summary = result["scrape_summary"]
        languages = result.get("languages", {})
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(f"# {repo['full_name']} ä»“åº“æŠ“å–æŠ¥å‘Š\n\n")
            
            f.write("## ä»“åº“ä¿¡æ¯\n\n")
            f.write(f"**æè¿°**: {repo.get('description', 'N/A')}\n")
            f.write(f"**ä¸»è¦è¯­è¨€**: {repo.get('language', 'N/A')}\n")
            f.write(f"**æ˜Ÿæ ‡æ•°**: {repo.get('stargazers_count', 0):,}\n")
            f.write(f"**Forkæ•°**: {repo.get('forks_count', 0):,}\n")
            f.write(f"**å¤§å°**: {repo.get('size', 0):,} KB\n")
            f.write(f"**åˆ›å»ºæ—¶é—´**: {repo.get('created_at', 'N/A')}\n")
            f.write(f"**æ›´æ–°æ—¶é—´**: {repo.get('updated_at', 'N/A')}\n")
            f.write(f"**ä¸»é¡µ**: {repo.get('homepage', 'N/A')}\n")
            f.write(f"**è®¸å¯è¯**: {repo.get('license', 'N/A')}\n\n")
            
            if languages:
                f.write("## ç¼–ç¨‹è¯­è¨€ç»Ÿè®¡\n\n")
                total_bytes = sum(languages.values())
                for lang, bytes_count in sorted(languages.items(), key=lambda x: x[1], reverse=True):
                    percentage = (bytes_count / total_bytes) * 100 if total_bytes > 0 else 0
                    f.write(f"- {lang}: {percentage:.1f}% ({bytes_count:,} bytes)\n")
                f.write("\n")
            
            f.write("## æŠ“å–ç»Ÿè®¡\n\n")
            f.write(f"**æŠ“å–æ—¶é—´**: {summary['scraped_at']}\n")
            f.write(f"**æ€»æ–‡ä»¶æ•°**: {summary['total_files_found']}\n")
            f.write(f"**æ–‡æ¡£æ–‡ä»¶æ•°**: {summary['documentation_files']}\n")
            f.write(f"**å·²æŠ“å–æ–‡ä»¶æ•°**: {summary['extracted_files']}\n\n")
            
            f.write("## æŠ“å–çš„æ–‡ä»¶\n\n")
            for file_data in result["files"][:20]:  # åªæ˜¾ç¤ºå‰20ä¸ª
                if file_data.get("status") == "success":
                    file_type = file_data.get("file_type", "unknown")
                    size = file_data.get("size", 0)
                    f.write(f"- [{file_data['path']}]({file_data.get('html_url', '')}) ")
                    f.write(f"({file_type}, {size} bytes)\n")
            
            if len(result["files"]) > 20:
                f.write(f"\n... ä»¥åŠå…¶ä»– {len(result['files']) - 20} ä¸ªæ–‡ä»¶\n")


# ä¾¿æ·å‡½æ•°
async def scrape_github_repository(owner: str, repo: str, 
                                 max_files: int = 100, 
                                 include_code: bool = True,
                                 config: GitHubConfig = None) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šæŠ“å–GitHubä»“åº“
    
    Args:
        owner: ä»“åº“æ‰€æœ‰è€…
        repo: ä»“åº“åç§°
        max_files: æœ€å¤§æ–‡ä»¶æ•°
        include_code: æ˜¯å¦åŒ…å«ä»£ç æ–‡ä»¶
        config: é…ç½®å¯¹è±¡
        
    Returns:
        æŠ“å–ç»“æœ
    """
    async with GitHubRepoScraper(config) as scraper:
        return await scraper.scrape_repository_documentation(owner, repo, max_files, include_code)


async def get_github_repository_info(owner: str, repo: str, config: GitHubConfig = None) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šè·å–GitHubä»“åº“ä¿¡æ¯
    
    Args:
        owner: ä»“åº“æ‰€æœ‰è€…
        repo: ä»“åº“åç§°
        config: é…ç½®å¯¹è±¡
        
    Returns:
        ä»“åº“ä¿¡æ¯
    """
    async with GitHubRepoScraper(config) as scraper:
        return await scraper.get_repository_info(owner, repo)
