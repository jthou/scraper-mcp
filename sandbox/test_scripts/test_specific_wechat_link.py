#!/usr/bin/env python3
"""
æµ‹è¯•ç‰¹å®šå¾®ä¿¡æ–‡ç« é“¾æ¥

ä½¿ç”¨çœŸå®çš„æœç‹—å¾®ä¿¡æ–‡ç« é“¾æ¥è¿›è¡Œæµ‹è¯•
"""

import asyncio
import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

from src.core.wechat_scraper import WeChatScraper


async def test_specific_wechat_link():
    """æµ‹è¯•ç‰¹å®šçš„å¾®ä¿¡æ–‡ç« é“¾æ¥"""
    print("ğŸ”— æµ‹è¯•ç‰¹å®šå¾®ä¿¡æ–‡ç« é“¾æ¥")
    print("=" * 40)
    
    scraper = WeChatScraper()
    
    try:
        # è®¾ç½®æµè§ˆå™¨
        print("\n1. è®¾ç½®æµè§ˆå™¨...")
        setup_result = await scraper.setup_browser(headless=False, persistent=False)
        print(f"   ç»“æœ: {setup_result}")
        
        if setup_result["status"] != "success":
            print("âŒ æµè§ˆå™¨è®¾ç½®å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
            return
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path(__file__).parent / "specific_wechat_test"
        output_dir.mkdir(exist_ok=True)
        print(f"\n2. è¾“å‡ºç›®å½•: {output_dir}")
        
        # è¿™é‡Œæ˜¯ä¸€ä¸ªçœŸå®çš„æœç‹—å¾®ä¿¡æ–‡ç« é“¾æ¥ç¤ºä¾‹
        # ä½ å¯ä»¥æ›¿æ¢æˆä»»ä½•ä½ æƒ³æµ‹è¯•çš„é“¾æ¥
        test_url = "https://weixin.sogou.com/link?url=dn9a_-gY295K0Rci_xozVXfdMkSQTLW6cwJThYulHEtVjXrGTiVgS-RU6ljlTvJpOQfAfK4l7_65z41o-wcdAVqXa8Fplpd9952kvnRUuUGmJJKhudQ35mGjx4ciicfy_t6uMaCgkDBcJat_Dw3Ktt9Z3CebSf58m4l0myOsAm_R-JrxCE85wcX0SQNdi8xJjoL3tZWFVb"
        
        print(f"\n3. æµ‹è¯•é“¾æ¥:")
        print(f"   {test_url}")
        
        # è®¿é—®é“¾æ¥
        print(f"\n4. è®¿é—®é“¾æ¥...")
        await scraper.page.goto(test_url)
        await scraper.page.wait_for_load_state("networkidle")
        
        # ç­‰å¾…é¡µé¢åŠ è½½
        await asyncio.sleep(5)
        
        # è·å–é¡µé¢ä¿¡æ¯
        title = await scraper.page.title()
        current_url = scraper.page.url
        content = await scraper.page.content()
        
        print(f"   é¡µé¢æ ‡é¢˜: {title}")
        print(f"   å½“å‰URL: {current_url}")
        print(f"   å†…å®¹é•¿åº¦: {len(content)}")
        
        # æ£€æŸ¥é¡µé¢çŠ¶æ€
        if "æœç‹—æœç´¢" in title:
            print(f"   âš ï¸ é¡µé¢è¢«é‡å®šå‘åˆ°æœç‹—æœç´¢")
        elif "éªŒè¯ç " in content or "captcha" in content.lower():
            print(f"   âš ï¸ é¡µé¢åŒ…å«éªŒè¯ç ")
        elif "è¯·åœ¨å¾®ä¿¡ä¸­æ‰“å¼€" in content:
            print(f"   âš ï¸ é¡µé¢è¦æ±‚å¾®ä¿¡å®¢æˆ·ç«¯æ‰“å¼€")
        elif "mp.weixin.qq.com" in current_url:
            print(f"   âœ… æˆåŠŸé‡å®šå‘åˆ°å¾®ä¿¡æ–‡ç« ")
        else:
            print(f"   â“ é¡µé¢çŠ¶æ€æœªçŸ¥")
        
        # æ˜¾ç¤ºé¡µé¢å†…å®¹é¢„è§ˆ
        print(f"\n5. é¡µé¢å†…å®¹é¢„è§ˆ:")
        content_preview = content[:500] if len(content) > 500 else content
        print(f"   {content_preview}...")
        
        # å°è¯•ç”ŸæˆPDF
        print(f"\n6. å°è¯•ç”ŸæˆPDF...")
        pdf_result = await scraper.print_page_to_pdf(test_url)
        
        if pdf_result["status"] == "success":
            print(f"   âœ… PDFç”ŸæˆæˆåŠŸ")
            print(f"   ğŸ“ æ–‡ä»¶è·¯å¾„: {pdf_result['pdf_path']}")
            
            # æ£€æŸ¥PDFæ–‡ä»¶
            pdf_path = Path(pdf_result['pdf_path'])
            if pdf_path.exists():
                file_size = pdf_path.stat().st_size
                print(f"   ğŸ“Š æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
                
                if file_size > 50000:
                    print(f"   âœ… PDFæ–‡ä»¶å¤§å°æ­£å¸¸ï¼Œå¯èƒ½åŒ…å«çœŸå®å†…å®¹")
                    
                    # å°è¯•è½¬æ¢ä¸ºMarkdown
                    print(f"   ğŸ“ å°è¯•è½¬æ¢ä¸ºMarkdown...")
                    markdown_result = await scraper.pdf_to_markdown(str(pdf_path))
                    
                    if markdown_result["status"] == "success":
                        print(f"   âœ… Markdownè½¬æ¢æˆåŠŸ")
                        print(f"   ğŸ“„ å†…å®¹é•¿åº¦: {len(markdown_result['markdown_content'])}")
                        
                        # æ˜¾ç¤ºå†…å®¹é¢„è§ˆ
                        print(f"\n7. å†…å®¹é¢„è§ˆ:")
                        content_preview = markdown_result['markdown_content'][:300]
                        print(f"   {content_preview}...")
                        
                        # ä¿å­˜æ–‡ä»¶
                        pdf_dir = output_dir / "pdfs"
                        markdown_dir = output_dir / "markdown"
                        pdf_dir.mkdir(exist_ok=True)
                        markdown_dir.mkdir(exist_ok=True)
                        
                        # å¤åˆ¶PDFæ–‡ä»¶
                        import shutil
                        target_pdf = pdf_dir / "wechat_article.pdf"
                        shutil.copy2(pdf_path, target_pdf)
                        
                        # ä¿å­˜Markdownæ–‡ä»¶
                        markdown_content = f"""# å¾®ä¿¡æ–‡ç« æµ‹è¯•

**æ¥æº**: {test_url}
**ä¿å­˜æ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}
**æ¥æºå¹³å°**: æœç‹—å¾®ä¿¡æœç´¢

---

{markdown_result['markdown_content']}
"""
                        
                        markdown_file = markdown_dir / "wechat_article.md"
                        with open(markdown_file, 'w', encoding='utf-8') as f:
                            f.write(markdown_content)
                        
                        print(f"   âœ… æ–‡ä»¶ä¿å­˜æˆåŠŸ")
                        print(f"   ğŸ“ PDF: {target_pdf}")
                        print(f"   ğŸ“„ Markdown: {markdown_file}")
                    else:
                        print(f"   âŒ Markdownè½¬æ¢å¤±è´¥: {markdown_result['message']}")
                else:
                    print(f"   âš ï¸ PDFæ–‡ä»¶è¾ƒå°ï¼Œå¯èƒ½æ˜¯éªŒè¯é¡µé¢")
            else:
                print(f"   âŒ PDFæ–‡ä»¶ä¸å­˜åœ¨")
        else:
            print(f"   âŒ PDFç”Ÿæˆå¤±è´¥: {pdf_result['message']}")
        
        # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶
        print(f"\n8. ç”Ÿæˆçš„æ–‡ä»¶:")
        if output_dir.exists():
            for item in output_dir.rglob("*"):
                if item.is_file():
                    print(f"   ğŸ“„ {item.relative_to(output_dir)}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†èµ„æº
        print("\n9. æ¸…ç†èµ„æº...")
        try:
            await scraper.cleanup()
            print("   âœ… èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            print(f"   âš ï¸ èµ„æºæ¸…ç†è­¦å‘Š: {e}")
    
    print("\nğŸ‰ ç‰¹å®šå¾®ä¿¡æ–‡ç« é“¾æ¥æµ‹è¯•å®Œæˆï¼")


async def main():
    """ä¸»å‡½æ•°"""
    try:
        await test_specific_wechat_link()
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    asyncio.run(main())
