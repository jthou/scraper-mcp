#!/usr/bin/env python3
"""
å¾®ä¿¡å†…å®¹ä¸‹è½½æµ‹è¯•

æ¼”ç¤ºå¾®ä¿¡å†…å®¹çš„æœç´¢å’Œä¸‹è½½åŠŸèƒ½
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

from src.core.wechat_scraper import WeChatScraper


async def test_wechat_download():
    """æµ‹è¯•å¾®ä¿¡å†…å®¹ä¸‹è½½"""
    print("ğŸ“¥ å¾®ä¿¡å†…å®¹ä¸‹è½½æµ‹è¯•")
    print("=" * 40)
    
    scraper = WeChatScraper()
    
    try:
        # è®¾ç½®æµè§ˆå™¨
        print("\n1. è®¾ç½®æµè§ˆå™¨...")
        setup_result = await scraper.setup_browser(headless=False, persistent=False)
        print(f"   ç»“æœ: {setup_result}")
        
        if setup_result["status"] != "success":
            print("âŒ æµè§ˆå™¨è®¾ç½®å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
            return
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path(__file__).parent / "wechat_download_test"
        output_dir.mkdir(exist_ok=True)
        print(f"\n2. è¾“å‡ºç›®å½•: {output_dir}")
        
        # æœç´¢å¾®ä¿¡å†…å®¹
        print("\n3. æœç´¢å¾®ä¿¡å†…å®¹...")
        search_result = await scraper.search_wechat("Pythonç¼–ç¨‹", max_pages=1)
        print(f"   ç»“æœ: {search_result['status']}")
        
        if search_result["status"] == "success":
            print(f"   âœ… æ‰¾åˆ° {search_result['total_results']} ä¸ªç»“æœ")
            
            # ä¸‹è½½å‰3ä¸ªç»“æœ
            results = search_result.get('results', [])
            for i, item in enumerate(results[:3], 1):
                print(f"\n4.{i} ä¸‹è½½ç¬¬ {i} ä¸ªç»“æœ...")
                print(f"   æ ‡é¢˜: {item['title']}")
                print(f"   é“¾æ¥: {item['link']}")
                
                # ä¸‹è½½å•ä¸ªå†…å®¹
                download_result = await scraper.download_and_save_content(
                    item['link'], 
                    output_dir, 
                    item['title']
                )
                
                if download_result["status"] == "success":
                    print(f"   âœ… ä¸‹è½½æˆåŠŸ: {download_result['base_name']}")
                    print(f"   ğŸ“ PDF: {download_result['files']['pdf']}")
                    print(f"   ğŸ“„ Markdown: {download_result['files']['markdown']}")
                else:
                    print(f"   âŒ ä¸‹è½½å¤±è´¥: {download_result['message']}")
                
                # ç­‰å¾…ä¸€ä¸‹é¿å…è¯·æ±‚è¿‡å¿«
                await asyncio.sleep(2)
            
            # æ˜¾ç¤ºä¸‹è½½ç›®å½•ç»“æ„
            print(f"\n5. ä¸‹è½½ç›®å½•ç»“æ„:")
            print(f"   ğŸ“ {output_dir}")
            if output_dir.exists():
                for item in output_dir.rglob("*"):
                    if item.is_file():
                        print(f"      ğŸ“„ {item.relative_to(output_dir)}")
            
        else:
            print(f"   âŒ æœç´¢å¤±è´¥: {search_result['message']}")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    finally:
        # æ¸…ç†èµ„æº
        print("\n6. æ¸…ç†èµ„æº...")
        try:
            await scraper.cleanup()
            print("   âœ… èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            print(f"   âš ï¸ èµ„æºæ¸…ç†è­¦å‘Š: {e}")
    
    print("\nğŸ‰ å¾®ä¿¡å†…å®¹ä¸‹è½½æµ‹è¯•å®Œæˆï¼")


async def main():
    """ä¸»å‡½æ•°"""
    try:
        await test_wechat_download()
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    asyncio.run(main())
