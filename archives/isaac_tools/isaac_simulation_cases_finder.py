#!/usr/bin/env python3
"""
Isaac Sim ä»¿çœŸæ¡ˆä¾‹æ–‡æ¡£ä¸“é¡¹æœç´¢å™¨
ä¸“é—¨å¯»æ‰¾å’Œä¸‹è½½Isaac Simçš„ä»¿çœŸæ¡ˆä¾‹ã€æ•™ç¨‹å’Œç¤ºä¾‹æ–‡æ¡£
"""

import asyncio
import aiohttp
import json
from datetime import datetime
from pathlib import Path
import hashlib
from urllib.parse import urljoin, urlparse
from playwright.async_api import async_playwright
import re
from bs4 import BeautifulSoup

class IsaacSimCasesFinder:
    def __init__(self, output_dir="isaac_simulation_cases"):
        self.output_dir = Path(output_dir)
        self.pdf_dir = self.output_dir / "pdfs" 
        self.pdf_dir.mkdir(parents=True, exist_ok=True)
        
        self.found_urls = set()
        self.downloaded_files = []
        self.errors = []
        self.success_count = 0
        self.error_count = 0
        
    async def search_isaac_simulation_cases(self):
        """æœç´¢Isaac Simä»¿çœŸæ¡ˆä¾‹çš„å¤šç§æ¥æº"""
        
        print("ğŸ” ä¸“é¡¹æœç´¢Isaac Simä»¿çœŸæ¡ˆä¾‹æ–‡æ¡£...")
        
        # å¤šç§æœç´¢ç­–ç•¥
        search_strategies = [
            self.search_github_docs(),
            self.search_nvidia_developer(),
            self.search_isaac_lab_examples(),
            self.search_omniverse_tutorials(),
            self.search_isaac_ros_examples()
        ]
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æœç´¢ç­–ç•¥
        await asyncio.gather(*search_strategies, return_exceptions=True)
        
        print(f"ğŸ¯ æ€»å…±å‘ç° {len(self.found_urls)} ä¸ªä»¿çœŸæ¡ˆä¾‹ç›¸å…³URL")
        return list(self.found_urls)
    
    async def search_github_docs(self):
        """æœç´¢GitHubä¸Šçš„Isaacæ–‡æ¡£"""
        print("ğŸ“š æœç´¢GitHubæ–‡æ¡£...")
        
        github_sources = [
            "https://isaac-sim.github.io/IsaacLab/",
            "https://isaac-sim.github.io/IsaacLab/main/",
            "https://nvidia-isaac-ros.github.io/"
        ]
        
        async with async_playwright() as p:
            browser = await p.chromium.launch()
            
            for source in github_sources:
                try:
                    page = await browser.new_page()
                    print(f"  ğŸ” æ£€æŸ¥: {source}")
                    
                    response = await page.goto(source, timeout=20000, wait_until="networkidle")
                    if response and response.status < 400:
                        await self.extract_simulation_links(page, source)
                    
                    await page.close()
                    
                except Exception as e:
                    print(f"  âŒ GitHubæœç´¢é”™è¯¯ {source}: {e}")
            
            await browser.close()
    
    async def search_nvidia_developer(self):
        """æœç´¢NVIDIAå¼€å‘è€…ç½‘ç«™"""
        print("ğŸ¢ æœç´¢NVIDIAå¼€å‘è€…ç½‘ç«™...")
        
        nvidia_urls = [
            "https://developer.nvidia.com/isaac-sim",
            "https://docs.omniverse.nvidia.com/",
            "https://docs.omniverse.nvidia.com/isaacsim/",
            "https://docs.omniverse.nvidia.com/extensions/",
            "https://docs.omniverse.nvidia.com/kit/"
        ]
        
        async with async_playwright() as p:
            browser = await p.chromium.launch()
            
            for url in nvidia_urls:
                try:
                    page = await browser.new_page()
                    print(f"  ğŸ” æ£€æŸ¥: {url}")
                    
                    # è®¾ç½®æ›´é•¿çš„è¶…æ—¶æ—¶é—´
                    response = await page.goto(url, timeout=30000, wait_until="domcontentloaded")
                    if response and response.status < 400:
                        await asyncio.sleep(3)  # ç­‰å¾…åŠ¨æ€å†…å®¹åŠ è½½
                        await self.extract_simulation_links(page, url)
                    
                    await page.close()
                    
                except Exception as e:
                    print(f"  âŒ NVIDIAæœç´¢é”™è¯¯ {url}: {e}")
            
            await browser.close()
    
    async def search_isaac_lab_examples(self):
        """æ·±åº¦æœç´¢Isaac Labçš„ç¤ºä¾‹"""
        print("ğŸ§ª æ·±åº¦æœç´¢Isaac Labç¤ºä¾‹...")
        
        lab_paths = [
            "source/tutorials/",
            "source/tutorials/00_sim/",
            "source/tutorials/01_assets/", 
            "source/tutorials/02_scene/",
            "source/tutorials/03_envs/",
            "source/tutorials/04_sensors/",
            "source/tutorials/05_controllers/",
            "source/api/lab/envs/",
            "source/api/lab/sim/",
            "source/api/lab/assets/",
            "source/how-to/",
            "source/deployment/"
        ]
        
        base_url = "https://isaac-sim.github.io/IsaacLab/main/"
        
        async with async_playwright() as p:
            browser = await p.chromium.launch()
            
            for path in lab_paths:
                try:
                    full_url = urljoin(base_url, path)
                    page = await browser.new_page()
                    print(f"  ğŸ” æ£€æŸ¥Labè·¯å¾„: {path}")
                    
                    response = await page.goto(full_url, timeout=15000)
                    if response and response.status < 400:
                        await self.extract_simulation_links(page, full_url)
                        self.found_urls.add(full_url)
                    
                    await page.close()
                    
                except Exception as e:
                    print(f"  âŒ Labè·¯å¾„é”™è¯¯ {path}: {e}")
            
            await browser.close()
    
    async def search_omniverse_tutorials(self):
        """æœç´¢Omniverseæ•™ç¨‹"""
        print("ğŸ“ æœç´¢Omniverseæ•™ç¨‹...")
        
        tutorial_paths = [
            "app_isaacsim/app_isaacsim/tutorial_intro.html",
            "app_isaacsim/app_isaacsim/tutorial_gui_basics.html", 
            "app_isaacsim/app_isaacsim/tutorial_simple_objects.html",
            "app_isaacsim/app_isaacsim/tutorial_required_interface.html",
            "app_isaacsim/app_isaacsim/tutorial_core_api.html",
            "app_isaacsim/app_isaacsim/advanced_tutorials.html",
            "py/isaacsim/",
            "extensions/omni.isaac.sim/",
            "extensions/omni.isaac.core/"
        ]
        
        base_url = "https://docs.omniverse.nvidia.com/"
        
        # ç›´æ¥éªŒè¯è¿™äº›URL
        async with aiohttp.ClientSession() as session:
            for path in tutorial_paths:
                try:
                    full_url = urljoin(base_url, path)
                    async with session.head(full_url, timeout=10) as response:
                        if 200 <= response.status < 400:
                            self.found_urls.add(full_url)
                            print(f"  âœ… æ‰¾åˆ°: {path}")
                        else:
                            print(f"  âŒ æ— æ•ˆ: {path} ({response.status})")
                except:
                    print(f"  âŒ é”™è¯¯: {path}")
    
    async def search_isaac_ros_examples(self):
        """æœç´¢Isaac ROSç¤ºä¾‹"""
        print("ğŸ¤– æœç´¢Isaac ROSç¤ºä¾‹...")
        
        ros_paths = [
            "tutorials/",
            "concepts/",
            "performance/",
            "getting_started/",
            "repositories_and_packages/isaac_ros_apriltag/",
            "repositories_and_packages/isaac_ros_visual_slam/",
            "repositories_and_packages/isaac_ros_nvblox/",
            "repositories_and_packages/isaac_ros_image_pipeline/",
            "repositories_and_packages/isaac_ros_common/"
        ]
        
        base_url = "https://nvidia-isaac-ros.github.io/"
        
        for path in ros_paths:
            full_url = urljoin(base_url, path)
            self.found_urls.add(full_url)
    
    async def extract_simulation_links(self, page, base_url):
        """ä»é¡µé¢ä¸­æå–ä»¿çœŸç›¸å…³çš„é“¾æ¥"""
        try:
            content = await page.content()
            soup = BeautifulSoup(content, 'html.parser')
            
            # æŸ¥æ‰¾æ‰€æœ‰é“¾æ¥
            links = soup.find_all('a', href=True)
            
            for link in links:
                href = link['href']
                link_text = link.get_text().lower()
                
                # è¿‡æ»¤ä»¿çœŸæ¡ˆä¾‹ç›¸å…³çš„é“¾æ¥
                simulation_keywords = [
                    'tutorial', 'example', 'demo', 'case', 'simulation', 'sim',
                    'robot', 'manipulation', 'navigation', 'sensor', 'camera',
                    'physics', 'collision', 'dynamics', 'control', 'rl', 
                    'reinforcement', 'learning', 'training', 'environment',
                    'scene', 'asset', 'urdf', 'articulation', 'joint'
                ]
                
                if any(keyword in link_text for keyword in simulation_keywords) or \
                   any(keyword in href.lower() for keyword in simulation_keywords):
                    
                    full_url = urljoin(base_url, href)
                    
                    # è¿‡æ»¤æ‰ä¸ç›¸å…³çš„é“¾æ¥
                    if not any(exclude in full_url for exclude in [
                        'github.com', 'youtube.com', 'twitter.com', 'facebook.com',
                        'mailto:', 'javascript:', '#', '.zip', '.tar.gz'
                    ]):
                        self.found_urls.add(full_url)
                        
        except Exception as e:
            print(f"  âš ï¸ é“¾æ¥æå–é”™è¯¯: {e}")
    
    async def download_simulation_docs(self, urls):
        """ä¸‹è½½ä»¿çœŸæ–‡æ¡£"""
        print(f"ğŸš€ å¼€å§‹ä¸‹è½½ {len(urls)} ä¸ªä»¿çœŸæ¡ˆä¾‹æ–‡æ¡£...")
        
        async with async_playwright() as p:
            browser = await p.chromium.launch()
            
            for i, url in enumerate(urls, 1):
                try:
                    print(f"\nğŸ“„ è¿›åº¦: {i}/{len(urls)}")
                    print(f"ğŸ“¥ ä¸‹è½½: {url}")
                    
                    page = await browser.new_page()
                    
                    # è®¾ç½®é¡µé¢
                    await page.set_viewport_size({"width": 1920, "height": 1080})
                    await page.set_extra_http_headers({
                        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
                    })
                    
                    # å¯¼èˆªåˆ°é¡µé¢
                    response = await page.goto(url, wait_until="networkidle", timeout=30000)
                    
                    if not response or response.status >= 400:
                        raise Exception(f"HTTPé”™è¯¯: {response.status if response else 'No response'}")
                    
                    # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
                    await page.wait_for_load_state("networkidle")
                    await asyncio.sleep(2)
                    
                    # ç”Ÿæˆæ–‡ä»¶å
                    url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
                    parsed_url = urlparse(url)
                    path_part = parsed_url.path.strip('/').replace('/', '_').replace('.html', '')
                    if not path_part:
                        path_part = "index"
                    
                    filename = f"sim_case_{path_part}_{url_hash}.pdf"
                    pdf_path = self.pdf_dir / filename
                    
                    # ç”ŸæˆPDF
                    await page.pdf(
                        path=str(pdf_path),
                        format="A4",
                        print_background=True,
                        margin={"top": "1cm", "bottom": "1cm", "left": "1cm", "right": "1cm"}
                    )
                    
                    await page.close()
                    
                    # æ£€æŸ¥æ–‡ä»¶
                    file_size = pdf_path.stat().st_size
                    if file_size < 1000:
                        pdf_path.unlink()
                        raise Exception("PDFæ–‡ä»¶è¿‡å°")
                    
                    file_info = {
                        "url": url,
                        "filename": filename,
                        "size": file_size,
                        "category": self.categorize_url(url),
                        "download_time": datetime.now().isoformat()
                    }
                    
                    self.downloaded_files.append(file_info)
                    self.success_count += 1
                    
                    size_mb = file_size / (1024 * 1024)
                    print(f"âœ… æˆåŠŸ: {filename} ({size_mb:.1f} MB)")
                    
                    # è¿›åº¦æŠ¥å‘Š
                    if i % 10 == 0:
                        total_size = sum(f["size"] for f in self.downloaded_files) / (1024 * 1024)
                        print(f"ğŸ“Š è¿›åº¦æŠ¥å‘Š: æˆåŠŸ {self.success_count}, å¤±è´¥ {self.error_count}")
                        print(f"ğŸ’¾ å½“å‰å¤§å°: {total_size:.1f} MB")
                    
                    # å»¶è¿Ÿé¿å…è¿‡è½½
                    await asyncio.sleep(1)
                    
                except Exception as e:
                    error_info = {
                        "url": url,
                        "error": str(e),
                        "error_time": datetime.now().isoformat()
                    }
                    
                    self.errors.append(error_info)
                    self.error_count += 1
                    print(f"âŒ å¤±è´¥: {url} - {str(e)}")
            
            await browser.close()
    
    def categorize_url(self, url):
        """æ ¹æ®URLåˆ†ç±»æ–‡æ¡£ç±»å‹"""
        url_lower = url.lower()
        
        if 'tutorial' in url_lower:
            return "æ•™ç¨‹"
        elif 'example' in url_lower or 'demo' in url_lower:
            return "ç¤ºä¾‹"
        elif 'api' in url_lower:
            return "APIæ–‡æ¡£"
        elif 'isaac-ros' in url_lower:
            return "Isaac ROS"
        elif 'isaaclab' in url_lower:
            return "Isaac Lab"
        elif 'omniverse' in url_lower:
            return "Omniverse"
        else:
            return "å…¶ä»–"
    
    async def generate_report(self):
        """ç”Ÿæˆä¸‹è½½æŠ¥å‘Š"""
        total_size = sum(f["size"] for f in self.downloaded_files)
        total_size_mb = total_size / (1024 * 1024)
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        category_stats = {}
        for file_info in self.downloaded_files:
            category = file_info["category"]
            if category not in category_stats:
                category_stats[category] = {"count": 0, "size": 0}
            category_stats[category]["count"] += 1
            category_stats[category]["size"] += file_info["size"]
        
        report = {
            "æœç´¢æ—¶é—´": datetime.now().isoformat(),
            "å‘ç°URLæ€»æ•°": len(self.found_urls),
            "æˆåŠŸä¸‹è½½": self.success_count,
            "å¤±è´¥æ•°é‡": self.error_count,
            "æˆåŠŸç‡": f"{self.success_count / max(len(self.found_urls), 1) * 100:.1f}%",
            "æ€»å¤§å°MB": f"{total_size_mb:.1f}",
            "æŒ‰ç±»åˆ«ç»Ÿè®¡": {
                cat: {
                    "æ–‡ä»¶æ•°": stats["count"], 
                    "å¤§å°MB": f"{stats['size'] / (1024 * 1024):.1f}"
                }
                for cat, stats in category_stats.items()
            },
            "å‘ç°çš„URL": list(self.found_urls),
            "ä¸‹è½½æ–‡ä»¶": self.downloaded_files,
            "é”™è¯¯åˆ—è¡¨": self.errors
        }
        
        report_file = self.output_dir / "simulation_cases_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ‰ ä»¿çœŸæ¡ˆä¾‹æœç´¢ä¸‹è½½å®Œæˆ!")
        print(f"ğŸ“Š æˆåŠŸ: {self.success_count}, å¤±è´¥: {self.error_count}")
        print(f"ğŸ’¾ æ€»å¤§å°: {total_size_mb:.1f} MB")
        print(f"ğŸ“ æ–‡ä»¶ä½ç½®: {self.pdf_dir}")
        print(f"ğŸ“‹ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        
        if category_stats:
            print(f"\nğŸ“Š æŒ‰ç±»åˆ«ç»Ÿè®¡:")
            for category, stats in category_stats.items():
                size_mb = stats["size"] / (1024 * 1024)
                print(f"  ğŸ“‚ {category}: {stats['count']} ä¸ªæ–‡ä»¶, {size_mb:.1f} MB")

async def main():
    finder = IsaacSimCasesFinder()
    
    # 1. æœç´¢ä»¿çœŸæ¡ˆä¾‹URLs
    urls = await finder.search_isaac_simulation_cases()
    
    if urls:
        print(f"\nğŸ¯ æ‰¾åˆ° {len(urls)} ä¸ªä»¿çœŸæ¡ˆä¾‹ç›¸å…³URLï¼Œå¼€å§‹ä¸‹è½½...")
        # 2. ä¸‹è½½æ–‡æ¡£
        await finder.download_simulation_docs(urls)
        # 3. ç”ŸæˆæŠ¥å‘Š
        await finder.generate_report()
    else:
        print("âŒ æœªæ‰¾åˆ°ä»¿çœŸæ¡ˆä¾‹ç›¸å…³URL")

if __name__ == "__main__":
    asyncio.run(main())
