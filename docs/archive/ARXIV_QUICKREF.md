ğŸ”¬ ArXiv æ–‡çŒ®æœç´¢ä¸‹è½½ - å¿«é€Ÿå‚è€ƒå¡
==================================================

ğŸ“‹ æ ¸å¿ƒå‘½ä»¤
--------------------------------------------------
# å¿«é€Ÿäº¤äº’å¼å·¥å…· (åŒ…å«Markdownè½¬æ¢)
python3 arxiv_quick_tool.py

# é¢„å®šä¹‰æ”¶é›†å™¨
python3 collect_arxiv_content.py

# ç¤ºä¾‹è„šæœ¬
python3 examples/arxiv_search_example.py

# è½¬æ¢å™¨å¯¹æ¯”æµ‹è¯•
python3 test_converter_comparison.py

ğŸ“‹ Markdownè½¬æ¢åŠŸèƒ½ ğŸ†•
--------------------------------------------------
# æ”¯æŒçš„è½¬æ¢å™¨ï¼ˆæŒ‰æ¨èé¡ºåºï¼‰
1. pymupdf4llm - ç°ä»£åŒ–ï¼Œå¿«é€Ÿï¼Œè´¨é‡å¥½
2. pdfplumber  - è½»é‡çº§ï¼Œæ”¯æŒè¡¨æ ¼
3. pypandoc    - ä¼ ç»Ÿå·¥å…·ï¼ŒåŸºç¡€åŠŸèƒ½
4. marker      - å®éªŒæ€§ï¼Œæœ€é«˜è´¨é‡

# è½¬æ¢æ–¹æ³•é€‰æ‹©
convert_method = "pdf"     # PDFè½¬æ¢ï¼ˆæ¨èï¼‰
convert_method = "tex"     # TeXæºç è½¬æ¢
convert_method = "both"    # ä¸¤ç§éƒ½è¯•

ğŸ“‹ ç¼–ç¨‹æ¥å£
--------------------------------------------------
from core.arxiv_searcher import ArxivSearcher

# åˆ›å»ºæœç´¢å™¨
searcher = ArxivSearcher()

# æœç´¢å¹¶è½¬æ¢ä¸ºMarkdownï¼ˆä¸€ç«™å¼ï¼‰
result = await searcher.download_and_convert_to_markdown(
    paper,
    convert_method="pdf"  # pdf/tex/both
)

# æ‰¹é‡è½¬æ¢
result = await searcher.batch_convert_to_markdown(
    papers, 
    convert_method="pdf"
)

# æŒ‡å®šè½¬æ¢å™¨
result = searcher.convert_pdf_to_markdown(
    pdf_path,
    converter="pymupdf4llm"  # æˆ– pdfplumber/pypandoc
)

ğŸ“‹ å¸¸ç”¨å‚æ•°
--------------------------------------------------
ç±»åˆ«ä»£ç :
- cs.AI    - äººå·¥æ™ºèƒ½
- cs.LG    - æœºå™¨å­¦ä¹   
- cs.CV    - è®¡ç®—æœºè§†è§‰
- cs.CL    - è®¡ç®—è¯­è¨€å­¦
- cs.RO    - æœºå™¨äººå­¦
- cs.NE    - ç¥ç»ç½‘ç»œ
- stat.ML  - ç»Ÿè®¡æœºå™¨å­¦ä¹ 

æ’åºæ–¹å¼:
- relevance        - ç›¸å…³æ€§ï¼ˆé»˜è®¤ï¼‰
- lastUpdatedDate  - æœ€åæ›´æ–°æ—¥æœŸ
- submittedDate    - æäº¤æ—¥æœŸ

æ’åºé¡ºåº:
- descending - é™åºï¼ˆé»˜è®¤ï¼‰
- ascending  - å‡åº

ğŸ“‹ ç›®å½•ç»“æ„
--------------------------------------------------
K-Vault/ArXiv/
â”œâ”€â”€ pdfs/              # PDFæ–‡ä»¶
â”œâ”€â”€ metadata/          # å…ƒæ•°æ®JSON
â”œâ”€â”€ markdown/          # ğŸ†• Markdownè½¬æ¢æ–‡ä»¶
â”‚   â”œâ”€â”€ *_pymupdf.md   # PyMuPDF4LLMè½¬æ¢
â”‚   â”œâ”€â”€ *_pdfplumber.md # pdfplumberè½¬æ¢
â”‚   â””â”€â”€ *_pandoc.md    # pypandocè½¬æ¢
â”œâ”€â”€ tex_sources/       # ğŸ†• TeXæºç æ–‡ä»¶
â”œâ”€â”€ progress.json      # ä¸‹è½½è¿›åº¦
â”œâ”€â”€ search_cache.json  # æœç´¢ç¼“å­˜
â””â”€â”€ download_summary.json

ğŸ“‹ å¿«é€Ÿç¤ºä¾‹
--------------------------------------------------
# åŸºç¡€æœç´¢
await searcher.search_arxiv("transformer")

# åˆ†ç±»æœç´¢
await searcher.search_arxiv(
    "neural networks", 
    categories=["cs.AI", "cs.LG"]
)

# æ—¥æœŸç­›é€‰
await searcher.search_arxiv(
    "reinforcement learning",
    start_date="2023-01-01",
    end_date="2023-12-31"
)

# æœç´¢+ä¸‹è½½
await searcher.search_and_download(
    "computer vision",
    max_results=5,
    auto_download=True
)

ğŸ“‹ æ•…éšœæ’é™¤
--------------------------------------------------
# ä¾èµ–å®‰è£…ï¼ˆmacOSï¼‰
pip3 install --break-system-packages aiohttp feedparser

# æƒé™é—®é¢˜
chmod +x arxiv_quick_tool.py

# ç½‘ç»œé—®é¢˜
- æ£€æŸ¥ç½‘ç»œè¿æ¥
- è€ƒè™‘é™ä½å¹¶å‘æ•°ï¼šmax_concurrent=3
- å¢åŠ è¯·æ±‚é—´éš”ï¼šdelay_between_requests=2.0

ğŸ“‹ é…ç½®è°ƒä¼˜
--------------------------------------------------
# æœç´¢å™¨é…ç½®
searcher = ArxivSearcher(
    output_dir="./custom_output",  # è‡ªå®šä¹‰è¾“å‡ºç›®å½•
    max_concurrent=5,              # å¹¶å‘æ•°ï¼ˆé»˜è®¤5ï¼‰
    delay_between_requests=1.0     # è¯·æ±‚é—´éš”ç§’æ•°
)
