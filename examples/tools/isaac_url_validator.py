#!/usr/bin/env python3
"""
Isaac Sim URLéªŒè¯å™¨
æ£€æŸ¥å“ªäº›é“¾æ¥å®é™…æœ‰æ•ˆ
"""

import asyncio
import json
import aiohttp
from pathlib import Path
from urllib.parse import urljoin

async def check_url(session, url, timeout=10):
    """æ£€æŸ¥å•ä¸ªURLæ˜¯å¦æœ‰æ•ˆ"""
    try:
        async with session.head(url, timeout=timeout) as response:
            return {
                'url': url,
                'status': response.status,
                'valid': 200 <= response.status < 400,
                'content_type': response.headers.get('content-type', '')
            }
    except Exception as e:
        return {
            'url': url,
            'status': 'error',
            'valid': False,
            'error': str(e)
        }

async def discover_isaac_pages():
    """å‘ç°æœ‰æ•ˆçš„Isaac Labé¡µé¢"""
    
    base_urls = [
        "https://isaac-sim.github.io/IsaacLab/",
        "https://isaac-sim.github.io/IsaacLab/main/",
        "https://docs.omniverse.nvidia.com/isaacsim/latest/",
    ]
    
    # å¸¸è§é¡µé¢è·¯å¾„
    common_paths = [
        "index.html",
        "installation.html",
        "tutorial_intro.html",
        "features/overview.html",
        "getting_started.html",
        "api/index.html",
        "guides/index.html",
        "tutorials/index.html",
        "source/index.html",
        # Isaac Lab specific
        "source/setup/index.html",
        "source/features/index.html", 
        "source/tutorials/index.html",
        "source/api/index.html",
        # Documentation sections
        "setup/installation/index.html",
        "setup/sample.html",
        "features/actuators.html",
        "features/sensors.html",
        "features/environments.html",
        "tutorials/intro.html",
        "tutorials/core.html",
        "api/lab/index.html",
    ]
    
    all_urls_to_check = []
    
    # ç”Ÿæˆæ‰€æœ‰URLç»„åˆ
    for base_url in base_urls:
        all_urls_to_check.append(base_url)
        for path in common_paths:
            full_url = urljoin(base_url, path)
            all_urls_to_check.append(full_url)
    
    print(f"ğŸ” æ£€æŸ¥ {len(all_urls_to_check)} ä¸ªå¯èƒ½çš„URL...")
    
    # å¹¶å‘æ£€æŸ¥URL
    timeout = aiohttp.ClientTimeout(total=10)
    async with aiohttp.ClientSession(timeout=timeout) as session:
        tasks = [check_url(session, url) for url in all_urls_to_check]
        results = await asyncio.gather(*tasks, return_exceptions=True)
    
    # è¿‡æ»¤æœ‰æ•ˆç»“æœ
    valid_urls = []
    invalid_urls = []
    
    for result in results:
        if isinstance(result, dict):
            if result['valid']:
                valid_urls.append(result)
            else:
                invalid_urls.append(result)
    
    # æ’åºå¹¶æ˜¾ç¤ºç»“æœ
    valid_urls.sort(key=lambda x: x['url'])
    
    print(f"\nâœ… æ‰¾åˆ° {len(valid_urls)} ä¸ªæœ‰æ•ˆURL:")
    for i, result in enumerate(valid_urls[:20], 1):  # æ˜¾ç¤ºå‰20ä¸ª
        print(f"  {i}. {result['url']} (çŠ¶æ€: {result['status']})")
    
    if len(valid_urls) > 20:
        print(f"  ... è¿˜æœ‰ {len(valid_urls) - 20} ä¸ª")
    
    print(f"\nâŒ æ— æ•ˆURL: {len(invalid_urls)} ä¸ª")
    
    # ä¿å­˜ç»“æœ
    output_dir = Path("isaac_url_validation")
    output_dir.mkdir(exist_ok=True)
    
    # ä¿å­˜æœ‰æ•ˆURL
    valid_file = output_dir / "valid_urls.json"
    with open(valid_file, 'w', encoding='utf-8') as f:
        json.dump(valid_urls, f, ensure_ascii=False, indent=2)
    
    # ä¿å­˜æ— æ•ˆURL
    invalid_file = output_dir / "invalid_urls.json" 
    with open(invalid_file, 'w', encoding='utf-8') as f:
        json.dump(invalid_urls, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“ ç»“æœå·²ä¿å­˜:")
    print(f"  æœ‰æ•ˆURL: {valid_file}")
    print(f"  æ— æ•ˆURL: {invalid_file}")
    
    return valid_urls

async def main():
    """ä¸»å‡½æ•°"""
    valid_urls = await discover_isaac_pages()
    
    if valid_urls:
        print(f"\nğŸ¯ å»ºè®®ä¸‹è½½è¿™äº›æœ‰æ•ˆé¡µé¢:")
        for url_info in valid_urls[:10]:
            print(f"  {url_info['url']}")

if __name__ == "__main__":
    asyncio.run(main())
