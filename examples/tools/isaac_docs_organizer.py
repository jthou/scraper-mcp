#!/usr/bin/env python3
"""
Isaacæ–‡æ¡£æ•´ç†å·¥å…·
å°†æ‰€æœ‰Isaacç›¸å…³çš„PDFå’ŒMarkdownæ–‡æ¡£æ±‡èšåˆ°K-Vault/Isaacç›®å½•
"""

import os
import shutil
from pathlib import Path
import hashlib
import json
from datetime import datetime
import subprocess

class IsaacDocumentOrganizer:
    def __init__(self):
        self.base_dir = Path(".")
        self.k_vault_dir = Path("K-Vault/Isaac")
        self.pdf_dir = self.k_vault_dir / "pdfs"
        self.markdown_dir = self.k_vault_dir / "markdown"
        
        # åˆ›å»ºç›®æ ‡ç›®å½•
        self.pdf_dir.mkdir(parents=True, exist_ok=True)
        self.markdown_dir.mkdir(parents=True, exist_ok=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "pdf_files": 0,
            "markdown_files": 0,
            "duplicates_removed": 0,
            "total_size_mb": 0,
            "source_directories": [],
            "files_by_source": {}
        }
        
        # æ–‡ä»¶å»é‡ç”¨çš„å“ˆå¸Œè¡¨
        self.file_hashes = {}
        
    def calculate_file_hash(self, file_path):
        """è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼ç”¨äºå»é‡"""
        try:
            hash_md5 = hashlib.md5()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except:
            return None
    
    def find_isaac_directories(self):
        """æŸ¥æ‰¾æ‰€æœ‰Isaacç›¸å…³çš„ç›®å½•"""
        isaac_dirs = []
        
        # æŸ¥æ‰¾åŒ…å«isaacçš„ç›®å½•å
        for item in self.base_dir.iterdir():
            if item.is_dir() and 'isaac' in item.name.lower():
                isaac_dirs.append(item)
        
        # æŸ¥æ‰¾dataç›®å½•ä¸‹çš„isaacç›¸å…³ç›®å½•
        data_dir = self.base_dir / "data"
        if data_dir.exists():
            for item in data_dir.iterdir():
                if item.is_dir() and 'isaac' in item.name.lower():
                    isaac_dirs.append(item)
        
        print(f"ğŸ” å‘ç° {len(isaac_dirs)} ä¸ªIsaacç›¸å…³ç›®å½•:")
        for dir_path in isaac_dirs:
            print(f"  ğŸ“ {dir_path}")
        
        return isaac_dirs
    
    def organize_pdfs_from_directory(self, source_dir):
        """ä»æŒ‡å®šç›®å½•æ•´ç†PDFæ–‡ä»¶"""
        pdf_count = 0
        
        # æŸ¥æ‰¾PDFæ–‡ä»¶
        pdf_files = []
        
        # æ£€æŸ¥pdfså­ç›®å½•
        pdfs_subdir = source_dir / "pdfs"
        if pdfs_subdir.exists():
            pdf_files.extend(pdfs_subdir.glob("*.pdf"))
        
        # æ£€æŸ¥æ ¹ç›®å½•
        pdf_files.extend(source_dir.glob("*.pdf"))
        
        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰PDFæ–‡ä»¶
        for pdf_file in source_dir.rglob("*.pdf"):
            if pdf_file not in pdf_files:
                pdf_files.append(pdf_file)
        
        if not pdf_files:
            return 0
        
        print(f"  ğŸ“„ å‘ç° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
        
        source_stats = {
            "directory": str(source_dir),
            "pdf_count": 0,
            "size_mb": 0,
            "files": []
        }
        
        for pdf_file in pdf_files:
            try:
                # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
                file_hash = self.calculate_file_hash(pdf_file)
                
                if file_hash and file_hash in self.file_hashes:
                    print(f"    ğŸ”„ è·³è¿‡é‡å¤æ–‡ä»¶: {pdf_file.name}")
                    self.stats["duplicates_removed"] += 1
                    continue
                
                # ç”Ÿæˆæ–°çš„æ–‡ä»¶åï¼ŒåŒ…å«æ¥æºä¿¡æ¯
                source_name = source_dir.name.replace('_', '-')
                new_filename = f"{source_name}_{pdf_file.name}"
                
                # å¦‚æœæ–‡ä»¶åå¤ªé•¿ï¼Œä½¿ç”¨å“ˆå¸Œç¼©çŸ­
                if len(new_filename) > 100:
                    file_ext = pdf_file.suffix
                    name_part = new_filename[:80]
                    hash_part = file_hash[:8] if file_hash else "unknown"
                    new_filename = f"{name_part}_{hash_part}{file_ext}"
                
                target_path = self.pdf_dir / new_filename
                
                # é¿å…æ–‡ä»¶åå†²çª
                counter = 1
                while target_path.exists():
                    name_without_ext = target_path.stem
                    ext = target_path.suffix
                    target_path = self.pdf_dir / f"{name_without_ext}_{counter}{ext}"
                    counter += 1
                
                # å¤åˆ¶æ–‡ä»¶
                shutil.copy2(pdf_file, target_path)
                
                # è®°å½•æ–‡ä»¶ä¿¡æ¯
                file_size = pdf_file.stat().st_size
                file_size_mb = file_size / (1024 * 1024)
                
                source_stats["files"].append({
                    "original_name": pdf_file.name,
                    "new_name": target_path.name,
                    "size_mb": round(file_size_mb, 2)
                })
                
                source_stats["pdf_count"] += 1
                source_stats["size_mb"] += file_size_mb
                
                if file_hash:
                    self.file_hashes[file_hash] = str(target_path)
                
                pdf_count += 1
                self.stats["pdf_files"] += 1
                self.stats["total_size_mb"] += file_size_mb
                
                print(f"    âœ… {pdf_file.name} -> {target_path.name}")
                
            except Exception as e:
                print(f"    âŒ å¤åˆ¶å¤±è´¥ {pdf_file.name}: {e}")
        
        self.stats["files_by_source"][str(source_dir)] = source_stats
        return pdf_count
    
    def organize_markdown_files(self, source_dir):
        """æ•´ç†Markdownæ–‡ä»¶"""
        markdown_count = 0
        
        # æŸ¥æ‰¾Markdownæ–‡ä»¶
        markdown_files = []
        markdown_files.extend(source_dir.glob("*.md"))
        markdown_files.extend(source_dir.rglob("*.md"))
        
        if not markdown_files:
            return 0
        
        print(f"  ğŸ“ å‘ç° {len(markdown_files)} ä¸ªMarkdownæ–‡ä»¶")
        
        for md_file in markdown_files:
            try:
                # ç”Ÿæˆæ–°çš„æ–‡ä»¶å
                source_name = source_dir.name.replace('_', '-')
                new_filename = f"{source_name}_{md_file.name}"
                target_path = self.markdown_dir / new_filename
                
                # é¿å…æ–‡ä»¶åå†²çª
                counter = 1
                while target_path.exists():
                    name_without_ext = target_path.stem
                    ext = target_path.suffix
                    target_path = self.markdown_dir / f"{name_without_ext}_{counter}{ext}"
                    counter += 1
                
                # å¤åˆ¶æ–‡ä»¶
                shutil.copy2(md_file, target_path)
                markdown_count += 1
                self.stats["markdown_files"] += 1
                
                print(f"    âœ… {md_file.name} -> {target_path.name}")
                
            except Exception as e:
                print(f"    âŒ å¤åˆ¶å¤±è´¥ {md_file.name}: {e}")
        
        return markdown_count
    
    def organize_all_isaac_docs(self):
        """æ•´ç†æ‰€æœ‰Isaacæ–‡æ¡£"""
        print("ğŸš€ å¼€å§‹æ•´ç†Isaacæ–‡æ¡£åˆ°K-Vault...")
        print(f"ğŸ“ ç›®æ ‡ç›®å½•: {self.k_vault_dir}")
        print()
        
        # æŸ¥æ‰¾æ‰€æœ‰Isaacç›®å½•
        isaac_dirs = self.find_isaac_directories()
        
        if not isaac_dirs:
            print("âŒ æœªæ‰¾åˆ°Isaacç›¸å…³ç›®å½•")
            return
        
        print(f"\nğŸ“¦ å¼€å§‹æ•´ç†æ–‡æ¡£...")
        
        for source_dir in isaac_dirs:
            print(f"\nğŸ”„ å¤„ç†ç›®å½•: {source_dir}")
            self.stats["source_directories"].append(str(source_dir))
            
            # æ•´ç†PDFæ–‡ä»¶
            pdf_count = self.organize_pdfs_from_directory(source_dir)
            
            # æ•´ç†Markdownæ–‡ä»¶
            md_count = self.organize_markdown_files(source_dir)
            
            total_files = pdf_count + md_count
            if total_files > 0:
                print(f"  âœ… å®Œæˆ: {pdf_count} PDF + {md_count} Markdown = {total_files} æ–‡ä»¶")
            else:
                print(f"  âšª è·³è¿‡: æœªæ‰¾åˆ°æ–‡æ¡£æ–‡ä»¶")
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_organization_report()
    
    def generate_organization_report(self):
        """ç”Ÿæˆæ•´ç†æŠ¥å‘Š"""
        print(f"\nğŸ‰ Isaacæ–‡æ¡£æ•´ç†å®Œæˆ!")
        print(f"ğŸ“Š æ•´ç†ç»Ÿè®¡:")
        print(f"  ğŸ“„ PDFæ–‡ä»¶: {self.stats['pdf_files']} ä¸ª")
        print(f"  ğŸ“ Markdownæ–‡ä»¶: {self.stats['markdown_files']} ä¸ª")
        print(f"  ğŸ”„ å»é‡æ–‡ä»¶: {self.stats['duplicates_removed']} ä¸ª")
        print(f"  ğŸ’¾ æ€»å¤§å°: {self.stats['total_size_mb']:.1f} MB")
        print(f"  ğŸ“ æºç›®å½•: {len(self.stats['source_directories'])} ä¸ª")
        
        print(f"\nğŸ“ æ–‡æ¡£ä½ç½®:")
        print(f"  ğŸ“„ PDFæ–‡æ¡£: {self.pdf_dir}")
        print(f"  ğŸ“ Markdownæ–‡æ¡£: {self.markdown_dir}")
        
        # æŒ‰æ¥æºåˆ†ç»„ç»Ÿè®¡
        print(f"\nğŸ“Š æŒ‰æ¥æºç»Ÿè®¡:")
        for source, stats in self.stats["files_by_source"].items():
            if stats["pdf_count"] > 0:
                print(f"  ğŸ“‚ {Path(source).name}: {stats['pdf_count']} PDF, {stats['size_mb']:.1f} MB")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report = {
            "æ•´ç†æ—¶é—´": datetime.now().isoformat(),
            "ç»Ÿè®¡ä¿¡æ¯": self.stats,
            "ç›®æ ‡ç›®å½•": {
                "PDFç›®å½•": str(self.pdf_dir),
                "Markdownç›®å½•": str(self.markdown_dir)
            }
        }
        
        report_file = self.k_vault_dir / "isaac_docs_organization_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“‹ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        
        # ç”Ÿæˆç´¢å¼•æ–‡ä»¶
        self.generate_index_files()
    
    def generate_index_files(self):
        """ç”Ÿæˆç´¢å¼•æ–‡ä»¶"""
        # PDFç´¢å¼•
        pdf_index_content = f"""# Isaac PDFæ–‡æ¡£ç´¢å¼•

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ç»Ÿè®¡ä¿¡æ¯
- æ€»PDFæ–‡ä»¶: {self.stats['pdf_files']} ä¸ª
- æ€»å¤§å°: {self.stats['total_size_mb']:.1f} MB
- å»é‡æ–‡ä»¶: {self.stats['duplicates_removed']} ä¸ª

## æ–‡ä»¶åˆ—è¡¨
"""
        
        # æŒ‰æ¥æºåˆ†ç»„åˆ—å‡ºPDFæ–‡ä»¶
        for source, stats in self.stats["files_by_source"].items():
            if stats["pdf_count"] > 0:
                pdf_index_content += f"\n### {Path(source).name} ({stats['pdf_count']} æ–‡ä»¶, {stats['size_mb']:.1f} MB)\n"
                for file_info in stats["files"]:
                    pdf_index_content += f"- [{file_info['new_name']}](./pdfs/{file_info['new_name']}) ({file_info['size_mb']:.1f} MB)\n"
        
        pdf_index_file = self.k_vault_dir / "PDF_INDEX.md"
        with open(pdf_index_file, 'w', encoding='utf-8') as f:
            f.write(pdf_index_content)
        
        # Markdownç´¢å¼•
        md_files = list(self.markdown_dir.glob("*.md"))
        md_index_content = f"""# Isaac Markdownæ–‡æ¡£ç´¢å¼•

ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ç»Ÿè®¡ä¿¡æ¯
- æ€»Markdownæ–‡ä»¶: {len(md_files)} ä¸ª

## æ–‡ä»¶åˆ—è¡¨
"""
        
        for md_file in sorted(md_files):
            md_index_content += f"- [{md_file.name}](./markdown/{md_file.name})\n"
        
        md_index_file = self.k_vault_dir / "MARKDOWN_INDEX.md"
        with open(md_index_file, 'w', encoding='utf-8') as f:
            f.write(md_index_content)
        
        print(f"ğŸ“‹ PDFç´¢å¼•: {pdf_index_file}")
        print(f"ğŸ“‹ Markdownç´¢å¼•: {md_index_file}")

def main():
    organizer = IsaacDocumentOrganizer()
    organizer.organize_all_isaac_docs()

if __name__ == "__main__":
    main()
