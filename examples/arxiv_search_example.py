#!/usr/bin/env python3
"""
ArXivæ–‡çŒ®æœç´¢ä¸ä¸‹è½½ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ArXivæœç´¢å™¨è¿›è¡Œæ–‡çŒ®æœç´¢å’Œä¸‹è½½
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

from src.core.arxiv_searcher import ArxivSearcher


async def example_basic_search():
    """åŸºç¡€æœç´¢ç¤ºä¾‹"""
    print("ğŸ” ArXivåŸºç¡€æœç´¢ç¤ºä¾‹")
    print("=" * 40)
    
    searcher = ArxivSearcher(Path("data/arxiv_demo"))
    
    # 1. åŸºç¡€æœç´¢
    print("\n1. æœç´¢æœºå™¨å­¦ä¹ ç›¸å…³è®ºæ–‡...")
    search_result = await searcher.search_arxiv(
        query="machine learning",
        max_results=5,
        sort_by="relevance"
    )
    
    if search_result["status"] == "success":
        papers = search_result["results"]
        print(f"   æ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡:")
        for i, paper in enumerate(papers, 1):
            print(f"   {i}. {paper['title'][:60]}...")
            print(f"      ID: {paper['arxiv_id']}, åˆ†ç±»: {paper['primary_category']}")
    
    return search_result


async def example_category_search():
    """åˆ†ç±»æœç´¢ç¤ºä¾‹"""
    print("\nğŸ¯ åˆ†ç±»æœç´¢ç¤ºä¾‹")
    print("=" * 40)
    
    searcher = ArxivSearcher(Path("data/arxiv_demo"))
    
    # 2. æŒ‰åˆ†ç±»æœç´¢
    print("\n2. æœç´¢è®¡ç®—æœºè§†è§‰è®ºæ–‡...")
    search_result = await searcher.search_arxiv(
        query="computer vision",
        max_results=3,
        categories=["cs.CV"],
        sort_by="submittedDate",
        sort_order="descending"
    )
    
    if search_result["status"] == "success":
        papers = search_result["results"]
        print(f"   æ‰¾åˆ° {len(papers)} ç¯‡è®¡ç®—æœºè§†è§‰è®ºæ–‡:")
        for paper in papers:
            print(f"   â€¢ {paper['title']}")
            print(f"     ä½œè€…: {', '.join(paper['authors'][:3])}{'...' if len(paper['authors']) > 3 else ''}")
            print(f"     å‘å¸ƒ: {paper['published'][:10] if paper['published'] else 'N/A'}")
    
    return search_result


async def example_download_papers():
    """ä¸‹è½½è®ºæ–‡ç¤ºä¾‹"""
    print("\nğŸ“¥ è®ºæ–‡ä¸‹è½½ç¤ºä¾‹")
    print("=" * 40)
    
    searcher = ArxivSearcher(Path("data/arxiv_demo"))
    
    # 3. æœç´¢å¹¶ä¸‹è½½
    print("\n3. æœç´¢å¹¶ä¸‹è½½æ·±åº¦å­¦ä¹ è®ºæ–‡...")
    result = await searcher.search_and_download(
        query="deep learning",
        max_results=3,
        categories=["cs.LG"],
        auto_download=True
    )
    
    if result["status"] in ["success", "partial"]:
        summary = result.get("download_summary", {})
        print(f"   ä¸‹è½½æ‘˜è¦:")
        print(f"   â€¢ æ€»è®ºæ–‡æ•°: {summary.get('total_papers', 0)}")
        print(f"   â€¢ æˆåŠŸä¸‹è½½: {summary.get('successful_downloads', 0)}")
        print(f"   â€¢ å·²å­˜åœ¨è·³è¿‡: {summary.get('skipped_papers', 0)}")
        print(f"   â€¢ ä¸‹è½½å¤±è´¥: {summary.get('failed_downloads', 0)}")
        print(f"   â€¢ æˆåŠŸç‡: {summary.get('success_rate', 0):.1f}%")
    
    return result


async def example_date_filtered_search():
    """æ—¥æœŸè¿‡æ»¤æœç´¢ç¤ºä¾‹"""
    print("\nğŸ“… æ—¥æœŸè¿‡æ»¤æœç´¢ç¤ºä¾‹")
    print("=" * 40)
    
    searcher = ArxivSearcher(Path("data/arxiv_demo"))
    
    # 4. æŒ‰æ—¥æœŸæœç´¢
    print("\n4. æœç´¢2024å¹´çš„è‡ªç„¶è¯­è¨€å¤„ç†è®ºæ–‡...")
    search_result = await searcher.search_arxiv(
        query="natural language processing",
        max_results=5,
        categories=["cs.CL"],
        start_date="2024-01-01",
        end_date="2024-12-31"
    )
    
    if search_result["status"] == "success":
        papers = search_result["results"]
        print(f"   æ‰¾åˆ° {len(papers)} ç¯‡2024å¹´NLPè®ºæ–‡:")
        for paper in papers:
            pub_date = paper['published'][:10] if paper['published'] else 'N/A'
            print(f"   â€¢ [{pub_date}] {paper['title'][:50]}...")
    
    return search_result


async def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸš€ ArXivæ–‡çŒ®æœç´¢ä¸ä¸‹è½½ç¤ºä¾‹")
    print("=" * 50)
    
    try:
        # è¿è¡Œå„ç§ç¤ºä¾‹
        await example_basic_search()
        await example_category_search()
        await example_download_papers()
        await example_date_filtered_search()
        
        print("\nâœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
        print("\nğŸ’¡ æç¤º:")
        print("   â€¢ PDFæ–‡ä»¶ä¿å­˜åœ¨: data/arxiv_demo/pdfs/")
        print("   â€¢ å…ƒæ•°æ®ä¿å­˜åœ¨: data/arxiv_demo/metadata/")
        print("   â€¢ è¿›åº¦æ–‡ä»¶: data/arxiv_demo/progress.json")
        print("   â€¢ æœç´¢ç¼“å­˜: data/arxiv_demo/search_cache.json")
        
    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹è¿è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    asyncio.run(main())
