#!/usr/bin/env python3
"""
çŸ¥ä¹å†…å®¹æœç´¢ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ScraperToolkitæœç´¢çŸ¥ä¹å†…å®¹
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "src"))

from src.core.scraper_toolkit import ScraperToolkit, ScrapingConfig, Platform


async def search_zhihu_content():
    """æœç´¢çŸ¥ä¹å†…å®¹ç¤ºä¾‹"""
    print("ğŸ” çŸ¥ä¹å†…å®¹æœç´¢ç¤ºä¾‹")
    print("=" * 40)
    
    # åˆ›å»ºé…ç½®
    config = ScrapingConfig(
        platform=Platform.ZHIHU,
        headless=False,  # æ˜¾ç¤ºæµè§ˆå™¨çª—å£
        persistent=False,
        max_pages=2,
        output_dir=Path("data/zhihu")
    )
    
    # åˆ›å»ºå·¥å…·åŒ…å®ä¾‹
    toolkit = ScraperToolkit(config)
    
    try:
        # 1. è®¾ç½®æµè§ˆå™¨
        print("\n1. è®¾ç½®æµè§ˆå™¨...")
        setup_result = await toolkit.setup_browser(Platform.ZHIHU)
        print(f"   ç»“æœ: {setup_result}")
        
        if setup_result["status"] != "success":
            print("âŒ æµè§ˆå™¨è®¾ç½®å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
            return
        
        # 2. æœç´¢å†…å®¹
        query = "RTX 5080"
        print(f"\n2. æœç´¢çŸ¥ä¹å†…å®¹: {query}")
        search_result = await toolkit.search(Platform.ZHIHU, query, max_pages=2)
        
        if search_result["status"] == "success":
            print(f"   âœ… æœç´¢æˆåŠŸ!")
            print(f"   æ€»ç»“æœæ•°: {search_result['total_results']}")
            
            # æ˜¾ç¤ºå‰3ä¸ªç»“æœ
            results = search_result.get('results', [])
            if results:
                print(f"\n3. å‰3ä¸ªæœç´¢ç»“æœ:")
                for i, item in enumerate(results[:3], 1):
                    print(f"   {i}. {item['title']}")
                    print(f"      ä½œè€…: {item['author']}")
                    print(f"      é“¾æ¥: {item['url']}")
                    print(f"      æ‘˜è¦: {item['summary'][:100]}...")
                    print()
                
                # 3. ä¸‹è½½ç¬¬ä¸€ä¸ªç»“æœ
                if results:
                    first_result = results[0]
                    print(f"4. ä¸‹è½½ç¬¬ä¸€ä¸ªç»“æœ...")
                    print(f"   æ ‡é¢˜: {first_result['title']}")
                    
                    download_result = await toolkit.download_content(
                        Platform.ZHIHU,
                        first_result['url'],
                        Path("data/zhihu"),
                        first_result['title']
                    )
                    
                    if download_result["status"] == "success":
                        print(f"   âœ… ä¸‹è½½æˆåŠŸ!")
                        print(f"   ğŸ“ PDF: {download_result['files']['pdf']}")
                        print(f"   ğŸ“„ Markdown: {download_result['files']['markdown']}")
                    else:
                        print(f"   âŒ ä¸‹è½½å¤±è´¥: {download_result['message']}")
            else:
                print(f"   âŒ æ²¡æœ‰æ‰¾åˆ°æœç´¢ç»“æœ")
        else:
            print(f"   âŒ æœç´¢å¤±è´¥: {search_result['message']}")
    
    except Exception as e:
        print(f"âŒ ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # æ¸…ç†èµ„æº
        print("\n5. æ¸…ç†èµ„æº...")
        await toolkit.cleanup()
        print("   âœ… èµ„æºæ¸…ç†å®Œæˆ")
    
    print("\nğŸ‰ çŸ¥ä¹å†…å®¹æœç´¢ç¤ºä¾‹å®Œæˆï¼")


async def main():
    """ä¸»å‡½æ•°"""
    try:
        await search_zhihu_content()
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç¤ºä¾‹è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nğŸ’¥ ç¤ºä¾‹æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    asyncio.run(main())
