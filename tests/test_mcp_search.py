#!/usr/bin/env python3
"""
æµ‹è¯•MCP Serverçš„çŸ¥ä¹æœç´¢åŠŸèƒ½
"""
import asyncio
import sys
import json
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from core.web_scraper import WebScraper
from utils.logger import Logger


async def test_mcp_search_tool():
    """æµ‹è¯•MCPæœç´¢å·¥å…·åŠŸèƒ½"""
    logger = Logger("MCPæœç´¢å·¥å…·æµ‹è¯•")
    
    # åˆ›å»ºWebScraperå®ä¾‹
    scraper = WebScraper()
    
    # å…ˆç™»å½•çŸ¥ä¹
    print("ğŸ” æ­£åœ¨ç™»å½•çŸ¥ä¹...")
    login_result = await scraper.login_zhihu(headless=False)
    if login_result["status"] != "success":
        print(f"âŒ ç™»å½•å¤±è´¥: {login_result['message']}")
        return False
    
    print("âœ… ç™»å½•æˆåŠŸï¼")
    
    # æµ‹è¯•æœç´¢åŠŸèƒ½
    test_queries = [
        {
            "query": "Pythonç¼–ç¨‹",
            "max_pages": 2,
            "min_relevance": 0.5
        },
        {
            "query": "æœºå™¨å­¦ä¹ ç®—æ³•",
            "max_pages": 1,
            "min_relevance": 0.6
        }
    ]
    
    for i, test_case in enumerate(test_queries, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ§ª æµ‹è¯• {i}: {test_case['query']}")
        print(f"{'='*60}")
        
        # è°ƒç”¨æœç´¢åŠŸèƒ½
        result = await scraper.search_zhihu(
            query=test_case["query"],
            max_pages=test_case["max_pages"],
            min_relevance=test_case["min_relevance"]
        )
        
        if result["status"] == "success":
            print(f"âœ… æœç´¢æˆåŠŸ!")
            print(f"ğŸ“Š æ€»ç»“æœæ•°: {result['total_results']}")
            print(f"ğŸ¯ ç¬¦åˆè¦æ±‚çš„ç»“æœæ•°: {result['filtered_results']}")
            
            # æ˜¾ç¤ºç¬¦åˆè¦æ±‚çš„æ‰€æœ‰é¡µé¢é“¾æ¥
            qualified_links = result.get("qualified_links", [])
            if qualified_links:
                print(f"\nğŸ“‹ ç¬¦åˆè¦æ±‚çš„æ‰€æœ‰é¡µé¢é“¾æ¥ ({len(qualified_links)}ä¸ª):")
                for j, link in enumerate(qualified_links, 1):
                    print(f"  {j}. {link}")
                
                # æ˜¾ç¤ºå‰3ä¸ªç»“æœçš„è¯¦ç»†ä¿¡æ¯
                results = result.get("results", [])
                print(f"\nğŸ“Š å‰3ä¸ªç»“æœè¯¦ç»†ä¿¡æ¯:")
                for j, item in enumerate(results[:3], 1):
                    print(f"\n  {j}. {item['title']}")
                    print(f"     ä½œè€…: {item['author']}")
                    print(f"     ç‚¹èµ: {item['vote_count']}")
                    print(f"     ç›¸å…³æ€§: {item['relevance_score']:.2f}")
                    print(f"     é“¾æ¥: {item['url']}")
                    if item['summary']:
                        print(f"     æ‘˜è¦: {item['summary'][:80]}...")
            else:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆè¦æ±‚çš„ç»“æœ")
        else:
            print(f"âŒ æœç´¢å¤±è´¥: {result['message']}")
    
    print(f"\n{'='*60}")
    print("ğŸ‰ MCPæœç´¢å·¥å…·æµ‹è¯•å®Œæˆï¼")
    print(f"{'='*60}")
    
    return True


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•MCP Serverçš„çŸ¥ä¹æœç´¢åŠŸèƒ½...")
    
    try:
        success = await test_mcp_search_tool()
        if success:
            print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        else:
            print("\nâŒ æµ‹è¯•å¤±è´¥ï¼")
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
